1. interpreter.py - DSL解释器核心
职责：DSL脚本的解析和执行
词法分析、语法分析
抽象语法树构建
脚本指令解释执行
对话状态管理

2. LLMNeed.py - LLM集成模块
职责：与大语言模型API交互
意图识别功能
API调用封装
错误处理和降级策略
提示词管理

3. spotServer.dsl - 服务端/业务逻辑
职责：协调整个系统流程
接收用户输入
调用LLM进行意图识别
调用解释器执行逻辑
返回最终响应

4. main.py - 程序入口
职责：启动应用程序
命令行界面
用户交互循环
程序初始化

5. README - 项目文档
职责：说明和使用指南
项目介绍
安装和运行说明
DSL语法文档

文件依赖关系
main.py → spotServer.dsl → interpreter.py
                         → LLMNeed.py


输入 = 用户自然语言 + DSL 脚本
输出 = 机器人应答文本

编程语言：优先选 Python
LLM API 选型
DSL 解析工具：新手推荐 lark（Python 库），不用从零写 lex/yacc；
若熟悉编译原理，也可直接用 ply（Python 版 yacc/lex）。



第一步：定义DSL语法（在纸上/白板上）

第二步：实现解释器核心

先实现词法分析和语法分析，将脚本转换成AST。

再实现解释执行器，能够遍历AST并执行 send_message, call_llm, set_state 等基本动作。

第三步：实现LLM集成模块

选择一个LLM（例如 OpenAI GPT-3.5-turbo， 或者免费的智谱AI、DeepSeek等）。

编写一个函数 recognize_intent(user_input: str) -> str，
 该函数构造Prompt，调用API，并返回识别出的意图字符串。

第四步：系统集成与测试

编写主循环：while True， 接收用户输入 -> 调用LLM识别意图 -> 根据当前对话状态和意图，找到DSL中对应的代码块 -> 交给解释器执行。


运行指令：python main.py

添加购票，需要带什么，调用真实的AI API
# 直接运行，不使用虚拟环境
"C:\Users\LENOVO\AppData\Local\Programs\Python\Python314\python.exe" main.py
# 先安装virtualenv
"C:\Users\LENOVO\AppData\Local\Programs\Python\Python314\python.exe" -m pip install virtualenv

# 使用virtualenv创建环境
"C:\Users\LENOVO\AppData\Local\Programs\Python\Python314\python.exe" -m virtualenv venv

命令行版本（在 back 目录）：

bash
cd back
python main.py
Web 版本（在 frontend 目录）：

bash
cd frontend 
python app.py

# 激活虚拟环境
venv\Scripts\activate




=====================================
测试桩 + TDD + 自动测试

步骤 1：编写测试用例（TDD）


步骤 2：实现测试桩

步骤 3：实现功能代码

步骤 4：运行测试

6. 工具推荐
单元测试：pytest、JUnit、Jest
测试桩 / 模拟：Mockito（Java）、unittest.mock（Python）
持续集成：Jenkins、GitHub Actions（自动运行测试）
测试报告：Allure、pytest-html

总结
测试桩：模拟依赖，隔离被测试模块。
TDD：先测试后编码，确保代码符合需求。
自动测试脚本：使用框架编写可重复执行的测试。
测试结果：分析失败原因，确保代码质量。

python test_suite.py 




静默